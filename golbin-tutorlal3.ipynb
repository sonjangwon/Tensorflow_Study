{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n",
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n",
      "b'Hello, TensorFlow!'\n",
      "[10, 32, 42]\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우의 기본적인 구성을 익힙니다.\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.constant: 말 그대로 상수입니다.\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "print(hello)\n",
    "\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "c = tf.add(a, b)  # a + b 로도 쓸 수 있음\n",
    "print(c)\n",
    "\n",
    "# 위에서 변수와 수식들을 정의했지만, 실행이 정의한 시점에서 실행되는 것은 아닙니다.\n",
    "# 다음처럼 Session 객제와 run 메소드를 사용할 때 계산이 됩니다.\n",
    "# 따라서 모델을 구성하는 것과, 실행하는 것을 분리하여 프로그램을 깔끔하게 작성할 수 있습니다.\n",
    "# 그래프를 실행할 세션을 구성합니다.\n",
    "sess = tf.Session()\n",
    "# sess.run: 설정한 텐서 그래프(변수나 수식 등등)를 실행합니다.\n",
    "print(sess.run(hello))\n",
    "print(sess.run([a, b, c]))\n",
    "\n",
    "# 세션을 닫습니다.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32)\n",
      "=== x_data ===\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "=== W ===\n",
      "[[ 0.86739218 -0.6852563 ]\n",
      " [-0.45369637  0.71654648]\n",
      " [ 0.29275715 -1.70424628]]\n",
      "=== b ===\n",
      "[[-0.5591141 ]\n",
      " [-0.83385259]]\n",
      "=== expr ===\n",
      "[[  0.2791568   -4.924016  ]\n",
      " [  2.12377739 -10.21762276]]\n"
     ]
    }
   ],
   "source": [
    "# 플레이스홀더와 변수의 개념을 익혀봅니다\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.placeholder: 계산을 실행할 때 입력값을 받는 변수로 사용합니다.\n",
    "# None 은 크기가 정해지지 않았음을 의미합니다.\n",
    "X = tf.placeholder(tf.float32, [None, 3])\n",
    "print(X)\n",
    "\n",
    "# X 플레이스홀더에 넣을 값 입니다.\n",
    "# 플레이스홀더에서 설정한 것 처럼, 두번째 차원의 요소의 갯수는 3개 입니다.\n",
    "x_data = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "# tf.Variable: 그래프를 계산하면서 최적화 할 변수들입니다. 이 값이 바로 신경망을 좌우하는 값들입니다.\n",
    "# tf.random_normal: 각 변수들의 초기값을 정규분포 랜덤 값으로 초기화합니다.\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([2, 1]))\n",
    "\n",
    "# 입력값과 변수들을 계산할 수식을 작성합니다.\n",
    "# tf.matmul 처럼 mat* 로 되어 있는 함수로 행렬 계산을 수행합니다.\n",
    "expr = tf.matmul(X, W) + b\n",
    "\n",
    "sess = tf.Session()\n",
    "# 위에서 설정한 Variable 들의 값들을 초기화 하기 위해\n",
    "# 처음에 tf.global_variables_initializer 를 한 번 실행해야 합니다.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"=== x_data ===\")\n",
    "print(x_data)\n",
    "print(\"=== W ===\")\n",
    "print(sess.run(W))\n",
    "print(\"=== b ===\")\n",
    "print(sess.run(b))\n",
    "print(\"=== expr ===\")\n",
    "# expr 수식에는 X 라는 입력값이 필요합니다.\n",
    "# 따라서 expr 실행시에는 이 변수에 대한 실제 입력값을 다음처럼 넣어줘야합니다.\n",
    "print(sess.run(expr, feed_dict={X: x_data}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", dtype=float32)\n",
      "Tensor(\"Y:0\", dtype=float32)\n",
      "0 4.98358 [ 1.32809114] [-0.48964119]\n",
      "1 0.0994985 [ 1.21772921] [-0.5229494]\n",
      "2 0.0392587 [ 1.22369504] [-0.5054512]\n",
      "3 0.0367307 [ 1.21709347] [-0.49383897]\n",
      "4 0.0349781 [ 1.21200848] [-0.48190856]\n",
      "5 0.0333165 [ 1.20689738] [-0.47033024]\n",
      "6 0.031734 [ 1.20192528] [-0.45902315]\n",
      "7 0.0302265 [ 1.19707096] [-0.44798863]\n",
      "8 0.0287908 [ 1.19233346] [-0.43721929]\n",
      "9 0.0274232 [ 1.18770993] [-0.42670882]\n",
      "10 0.0261206 [ 1.1831975] [-0.41645104]\n",
      "11 0.0248798 [ 1.17879355] [-0.40643984]\n",
      "12 0.023698 [ 1.17449546] [-0.3966693]\n",
      "13 0.0225723 [ 1.17030072] [-0.38713363]\n",
      "14 0.0215001 [ 1.16620684] [-0.3778272]\n",
      "15 0.0204789 [ 1.1622113] [-0.36874449]\n",
      "16 0.0195061 [ 1.15831184] [-0.35988012]\n",
      "17 0.0185795 [ 1.15450621] [-0.35122883]\n",
      "18 0.017697 [ 1.15079188] [-0.34278557]\n",
      "19 0.0168564 [ 1.14716709] [-0.3345452]\n",
      "20 0.0160557 [ 1.14362919] [-0.32650298]\n",
      "21 0.015293 [ 1.14017642] [-0.31865406]\n",
      "22 0.0145666 [ 1.13680673] [-0.31099382]\n",
      "23 0.0138747 [ 1.13351798] [-0.30351776]\n",
      "24 0.0132156 [ 1.13030827] [-0.29622141]\n",
      "25 0.0125879 [ 1.12717581] [-0.28910044]\n",
      "26 0.0119899 [ 1.12411857] [-0.28215069]\n",
      "27 0.0114204 [ 1.12113488] [-0.27536798]\n",
      "28 0.0108779 [ 1.11822283] [-0.26874834]\n",
      "29 0.0103612 [ 1.11538076] [-0.26228783]\n",
      "30 0.00986906 [ 1.11260724] [-0.25598255]\n",
      "31 0.00940026 [ 1.10990024] [-0.24982893]\n",
      "32 0.00895374 [ 1.10725832] [-0.24382323]\n",
      "33 0.00852844 [ 1.10467982] [-0.2379619]\n",
      "34 0.00812333 [ 1.10216343] [-0.23224145]\n",
      "35 0.00773748 [ 1.09970748] [-0.22665855]\n",
      "36 0.00736993 [ 1.09731066] [-0.22120982]\n",
      "37 0.00701987 [ 1.0949713] [-0.21589214]\n",
      "38 0.00668642 [ 1.0926882] [-0.21070224]\n",
      "39 0.00636881 [ 1.09046006] [-0.20563708]\n",
      "40 0.00606628 [ 1.08828545] [-0.2006937]\n",
      "41 0.00577813 [ 1.08616316] [-0.19586913]\n",
      "42 0.00550366 [ 1.0840919] [-0.19116057]\n",
      "43 0.00524222 [ 1.08207035] [-0.18656522]\n",
      "44 0.00499322 [ 1.08009744] [-0.18208033]\n",
      "45 0.00475604 [ 1.07817197] [-0.17770325]\n",
      "46 0.00453013 [ 1.07629275] [-0.1734314]\n",
      "47 0.00431494 [ 1.07445872] [-0.16926222]\n",
      "48 0.00410998 [ 1.07266879] [-0.16519327]\n",
      "49 0.00391475 [ 1.0709219] [-0.16122213]\n",
      "50 0.00372879 [ 1.06921697] [-0.15734646]\n",
      "51 0.00355168 [ 1.06755304] [-0.15356395]\n",
      "52 0.00338297 [ 1.06592917] [-0.14987236]\n",
      "53 0.00322228 [ 1.06434417] [-0.14626957]\n",
      "54 0.00306921 [ 1.06279743] [-0.14275333]\n",
      "55 0.00292342 [ 1.06128788] [-0.13932163]\n",
      "56 0.00278456 [ 1.05981445] [-0.13597246]\n",
      "57 0.00265229 [ 1.05837667] [-0.13270374]\n",
      "58 0.0025263 [ 1.05697334] [-0.12951365]\n",
      "59 0.0024063 [ 1.05560374] [-0.12640025]\n",
      "60 0.002292 [ 1.05426705] [-0.1233617]\n",
      "61 0.00218314 [ 1.05296242] [-0.1203962]\n",
      "62 0.00207944 [ 1.05168927] [-0.11750194]\n",
      "63 0.00198066 [ 1.05044675] [-0.11467727]\n",
      "64 0.00188658 [ 1.04923403] [-0.11192051]\n",
      "65 0.00179696 [ 1.0480504] [-0.10923003]\n",
      "66 0.0017116 [ 1.04689538] [-0.10660418]\n",
      "67 0.0016303 [ 1.04576802] [-0.10404149]\n",
      "68 0.00155286 [ 1.04466784] [-0.1015404]\n",
      "69 0.0014791 [ 1.043594] [-0.09909946]\n",
      "70 0.00140885 [ 1.04254603] [-0.09671718]\n",
      "71 0.00134192 [ 1.04152322] [-0.09439217]\n",
      "72 0.00127818 [ 1.04052508] [-0.09212302]\n",
      "73 0.00121747 [ 1.0395509] [-0.08990846]\n",
      "74 0.00115964 [ 1.03860009] [-0.08774714]\n",
      "75 0.00110455 [ 1.03767216] [-0.08563776]\n",
      "76 0.00105208 [ 1.03676653] [-0.08357908]\n",
      "77 0.00100211 [ 1.03588271] [-0.08156988]\n",
      "78 0.000954507 [ 1.03502011] [-0.07960898]\n",
      "79 0.000909168 [ 1.03417826] [-0.07769524]\n",
      "80 0.000865983 [ 1.03335667] [-0.07582749]\n",
      "81 0.000824844 [ 1.03255475] [-0.07400466]\n",
      "82 0.000785667 [ 1.03177214] [-0.07222563]\n",
      "83 0.000748346 [ 1.03100836] [-0.07048937]\n",
      "84 0.000712799 [ 1.03026295] [-0.06879485]\n",
      "85 0.000678941 [ 1.02953541] [-0.06714106]\n",
      "86 0.000646691 [ 1.0288254] [-0.06552702]\n",
      "87 0.000615973 [ 1.02813244] [-0.06395179]\n",
      "88 0.000586712 [ 1.02745616] [-0.06241442]\n",
      "89 0.00055884 [ 1.02679622] [-0.06091399]\n",
      "90 0.000532295 [ 1.02615201] [-0.05944967]\n",
      "91 0.000507011 [ 1.0255233] [-0.05802053]\n",
      "92 0.000482929 [ 1.02490973] [-0.05662575]\n",
      "93 0.000459987 [ 1.02431095] [-0.05526449]\n",
      "94 0.000438137 [ 1.02372658] [-0.05393596]\n",
      "95 0.000417328 [ 1.02315617] [-0.05263941]\n",
      "96 0.000397503 [ 1.02259958] [-0.05137399]\n",
      "97 0.000378621 [ 1.02205622] [-0.05013902]\n",
      "98 0.00036064 [ 1.02152598] [-0.04893371]\n",
      "99 0.000343509 [ 1.02100849] [-0.04775736]\n",
      "\n",
      "=== Test ===\n",
      "X: 5, Y: [ 5.05728531]\n",
      "X: 2.5, Y: [ 2.50476384]\n"
     ]
    }
   ],
   "source": [
    "# X 와 Y 의 상관관계를 분석하는 기초적인 선형 회귀 모델을 만들고 실행해봅니다.\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "# name: 나중에 텐서보드등으로 값의 변화를 추적하거나 살펴보기 쉽게 하기 위해 이름을 붙여줍니다.\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "# X 와 Y 의 상관 관계를 분석하기 위한 가설 수식을 작성합니다.\n",
    "# y = W * x + b\n",
    "# W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용했습니다.\n",
    "hypothesis = W * X + b\n",
    "\n",
    "# 손실 함수를 작성합니다.\n",
    "# mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 정합니다.\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 경사 하강법 최적화를 수행합니다.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "# 비용을 최소화 하는 것이 최종 목표\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "# 세션을 생성하고 초기화합니다.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # 최적화를 100번 수행합니다.\n",
    "    for step in range(100):\n",
    "        # sess.run 을 통해 train_op 와 cost 그래프를 계산합니다.\n",
    "        # 이 때, 가설 수식에 넣어야 할 실제값을 feed_dict 을 통해 전달합니다.\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "\n",
    "    # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인해봅니다.\n",
    "    print(\"\\n=== Test ===\")\n",
    "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
    "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
